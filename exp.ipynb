{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b9a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3b1d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m    103\u001b[39m   loss = criterion(pred, r)\n\u001b[32m    104\u001b[39m   optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m   \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m   optimizer.step()\n\u001b[32m    107\u001b[39m val_loss = evaluate(val_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/fall-25/deep-learning/final-project/movie-recommender/.venv/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/fall-25/deep-learning/final-project/movie-recommender/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/fall-25/deep-learning/final-project/movie-recommender/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Neural Collaborative Filtering cell (to be added at index 1)\n",
    "\n",
    "# paths (adjust if needed)\n",
    "ratings_path = \"../ml-32m/ratings.csv\"\n",
    "movies_path = \"../ml-32m/movies.csv\"\n",
    "\n",
    "# load data (pd is already imported in another cell)\n",
    "ratings = pd.read_csv(ratings_path)\n",
    "movies = pd.read_csv(movies_path)\n",
    "\n",
    "# keep only necessary columns\n",
    "ratings = ratings[['userId', 'movieId', 'rating']]\n",
    "\n",
    "# map ids to contiguous indices\n",
    "user_ids = ratings['userId'].unique()\n",
    "movie_ids = ratings['movieId'].unique()\n",
    "user2idx = {u: i for i, u in enumerate(user_ids)}\n",
    "movie2idx = {m: i for i, m in enumerate(movie_ids)}\n",
    "ratings['user_idx'] = ratings['userId'].map(user2idx)\n",
    "ratings['movie_idx'] = ratings['movieId'].map(movie2idx)\n",
    "\n",
    "# normalize ratings to [0,1]\n",
    "r_min, r_max = ratings['rating'].min(), ratings['rating'].max()\n",
    "ratings['rating_norm'] = (ratings['rating'] - r_min) / (r_max - r_min)\n",
    "\n",
    "# train / val split\n",
    "train_df, val_df = train_test_split(ratings, test_size=0.1, random_state=42)\n",
    "\n",
    "class RatingDataset(Dataset):\n",
    "  def __init__(self, df):\n",
    "    self.u = df['user_idx'].values.astype(np.int64)\n",
    "    self.i = df['movie_idx'].values.astype(np.int64)\n",
    "    self.r = df['rating_norm'].values.astype(np.float32)\n",
    "  def __len__(self):\n",
    "    return len(self.r)\n",
    "  def __getitem__(self, idx):\n",
    "    return self.u[idx], self.i[idx], self.r[idx]\n",
    "\n",
    "train_ds = RatingDataset(train_df)\n",
    "val_ds = RatingDataset(val_df)\n",
    "\n",
    "batch_size = 1024\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "class NCF(nn.Module):\n",
    "  def __init__(self, n_users, n_items, emb_size=64, hidden=[128,64,32]):\n",
    "    super().__init__()\n",
    "    self.user_emb = nn.Embedding(n_users, emb_size)\n",
    "    self.item_emb = nn.Embedding(n_items, emb_size)\n",
    "    layers = []\n",
    "    input_dim = emb_size * 2\n",
    "    for h in hidden:\n",
    "      layers.append(nn.Linear(input_dim, h))\n",
    "      layers.append(nn.ReLU(inplace=True))\n",
    "      input_dim = h\n",
    "    layers.append(nn.Linear(input_dim, 1))\n",
    "    self.mlp = nn.Sequential(*layers)\n",
    "    self._init_weights()\n",
    "  def _init_weights(self):\n",
    "    nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "    nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "    for m in self.mlp:\n",
    "      if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "  def forward(self, u, i):\n",
    "    u_e = self.user_emb(u)\n",
    "    i_e = self.item_emb(i)\n",
    "    x = torch.cat([u_e, i_e], dim=1)\n",
    "    out = self.mlp(x).squeeze(1)\n",
    "    return out\n",
    "\n",
    "n_users = len(user_ids)\n",
    "n_items = len(movie_ids)\n",
    "model = NCF(n_users, n_items, emb_size=64, hidden=[128,64,32]).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def evaluate(loader):\n",
    "  model.eval()\n",
    "  loss_sum = 0.0\n",
    "  n = 0\n",
    "  with torch.no_grad():\n",
    "    for u,i,r in loader:\n",
    "      u = u.to(device); i = i.to(device); r = r.to(device)\n",
    "      pred = model(u,i)\n",
    "      loss = criterion(pred, r)\n",
    "      loss_sum += loss.item() * r.size(0)\n",
    "      n += r.size(0)\n",
    "  return loss_sum / n\n",
    "\n",
    "# training loop (few epochs; increase epochs for better embeddings)\n",
    "epochs = 6\n",
    "for epoch in range(1, epochs+1):\n",
    "  model.train()\n",
    "  for u,i,r in train_loader:\n",
    "    u = u.to(device); i = i.to(device); r = r.to(device)\n",
    "    pred = model(u,i)\n",
    "    loss = criterion(pred, r)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  val_loss = evaluate(val_loader)\n",
    "  print(f\"Epoch {epoch}/{epochs}  val_mse={val_loss:.6f}\")\n",
    "\n",
    "# extract embeddings and map back to original ids\n",
    "user_embs = model.user_emb.weight.data.cpu().numpy()\n",
    "movie_embs = model.item_emb.weight.data.cpu().numpy()\n",
    "\n",
    "# create DataFrames with original ids\n",
    "user_embeddings_df = pd.DataFrame(user_embs)\n",
    "user_embeddings_df['userId'] = [int(user_ids[i]) for i in range(n_users)]\n",
    "user_embeddings_df = user_embeddings_df.set_index('userId')\n",
    "\n",
    "movie_embeddings_df = pd.DataFrame(movie_embs)\n",
    "movie_embeddings_df['movieId'] = [int(movie_ids[i]) for i in range(n_items)]\n",
    "movie_embeddings_df = movie_embeddings_df.set_index('movieId')\n",
    "\n",
    "\n",
    "# save embeddings (optional)\n",
    "user_embeddings_df.to_pickle(\"user_embeddings.pkl\")\n",
    "movie_embeddings_df.to_pickle(\"movie_embeddings.pkl\")\n",
    "\n",
    "print(\"user embeddings shape:\", user_embs.shape)\n",
    "print(\"movie embeddings shape:\", movie_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d954b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie-recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
